{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385401d9",
   "metadata": {},
   "source": [
    "# Chapter 4 Training Models\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "A linear model makes a prediction by simply computing a weighted sum of the input features, plus a constant called the *bias term*: \n",
    "\n",
    "$$ \\hat{y}=\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e347f2",
   "metadata": {},
   "source": [
    "In this equation: $\\hat{y}$ is the predicted value, $n$ is the number of features, $x_i$ is the i-th feature value, and $\\theta_j$ is the j-th model parameter (including the bias term $\\theta_0$).\n",
    "\n",
    "In vectorized form:\n",
    "$$ \\hat{y} = h_{\\mathbf{\\theta}}(\\mathbf{x})=\\mathbf{\\theta}\\cdot\\mathbf{x} $$\n",
    "\n",
    "If $\\mathbf{\\theta}$ and $\\mathbf{x}$ are column vectors, then the prediction is $\\hat{y}=\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}$, where $\\mathbf{\\theta}^{\\text{T}}$ is the transpose of $\\mathbf{\\theta}$ and $\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}$ is the matrix multiplication of the two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb89b2f",
   "metadata": {},
   "source": [
    "In order to train a linear regression model we first need a measure of how well the model fits the training data. The most common performance measure of a regression model is the Root Mean Square Error (RMSE). We need to find the value of $\\mathbf{\\theta}$ that minimizes the RMSE. Usually it's simpler to minimize the mean squared error (MSE) rather than the RMSE.\n",
    "\n",
    "The MSE of a linear regression hypothesis $h_{\\mathbf{\\theta}}$ on a training set $\\mathbf{X}$ is:\n",
    "\n",
    "$$ MSE(\\mathbf{X}, h_{\\mathbf{\\theta}})=\\frac{1}{m}\\sum^{m}_{i=1}\\big(\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}^{(i)}-y^{(i)}\\big)^{2}$$\n",
    "\n",
    "To find the value of $\\mathbf{\\theta}$ that minimizes the cost function, there is a analytical solution known as the *Normal Equation*.\n",
    "\n",
    "$$ \\hat{\\mathbf{\\theta}}=(\\mathbf{X}^{\\text{T}}\\mathbf{X})^{-1}\\mathbf{X}^{\\text{T}}\\mathbf{y} $$\n",
    "\n",
    "There are also iterative methods which we will look at later. \n",
    "\n",
    "Let's use the normal equation to perform regression on some test data in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df7e9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2.0, 0.0, 15.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYpklEQVR4nO3df6wlZX3H8c937wqIosDuGgiwLjQEg6IBblovmroWUxFR2tBYSO0uP+qVVixbbK1IUFJS16RN3TY2lasCu5HgD9DWGm1B5AZaLti7lN+IAgKCVtYFRRRWd/fbP2aOHI7n3DNn5pmZZ2ber2Rzz5kzc873zp39znO+zzPPmLsLANB+y+oOAABQDRI+AHQECR8AOoKEDwAdQcIHgI5YXuWHrVy50tesWVPlRwJA423duvVH7r6q6PtUmvDXrFmjxcXFKj8SABrPzB4O8T6UdACgI0j4ANARJHwA6AgSPgB0BAkfADqChA8AHUHCB4COIOEDQEeQ8AGgI0j4ANARYxO+mV1qZo+b2V1DXnufmbmZrSwnPABAKFla+JdLOmFwoZkdIul3JT0SOCYAQAnGJnx3v0HSE0Ne+pik90viprgA0AC5avhmdrKkx9z99gzrzprZopktbtu2Lc/HAQACmDjhm9nekj4o6UNZ1nf3OXefdvfpVasKT+cMAMgpTwv/NyQdKul2M3tI0sGSbjWzA0IGBgAIa+IboLj7nZJe1nueJv1pd/9RwLgAAIFlGZZ5paQFSUeY2aNmdlb5YQEAQhvbwnf308a8viZYNACA0nClLQB0BAkfADqChA8AHUHCB4COIOEDQEeQ8AGgI0j4ANARJHwA6AgSPgB0BAkfADqChA8AHUHCB4COIOEDQEeQ8AGgI0j4ANARJHwA6AgSPgB0BAkfADqChA8AHUHCB4COGJvwzexSM3vczO7qW/Z3ZvYtM7vDzL5kZvuWGiUAoLAsLfzLJZ0wsOxaSa9y91dL+rak8wPHBQAIbGzCd/cbJD0xsOwad9+ZPr1Z0sElxAYACChEDf9MSV8b9aKZzZrZopktbtu2LcDHAQDyKJTwzewCSTslXTFqHXefc/dpd59etWpVkY8DABSwPO+GZna6pJMkHe/uHiwiAEApciV8MztB0vslvcHdfx42JABAGbIMy7xS0oKkI8zsUTM7S9LHJe0j6Vozu83MPlFynACAgsa28N39tCGLP11CLACAEnGlLQB0BAkfADqChA8ABS0sSBs3Jj9jlntYJgAgSfLHHy/94hfSHntI110nzczUHdVwtPABoID5+STZ79qV/Jyfrzui0Uj4AFDA2rVJy35qKvm5dm3dEY1GSQcACpiZSco48/NJso+1nCOR8AGgsJmZuBN9DyUdAOgIEj4AdAQJHwA6goQPAB1BwgeAjiDhA8AEmjKNwjAMywSAjJo0jcIwtPABtFaR1viwbZs0jcIwtPABtFKR1viobXvTKPSWxzyNwjC08AG0UpHW+Khte9MoXHzx808gTanr08IH0EpFWuNLbTs4jUL/t4Hly6UzzpDWrYuztk/CB7CkhYVmTAw2qMikZpNs2/9tYNcu6ZJLpM2bf72EFMN+HJvwzexSSSdJetzdX5Uu21/S5yStkfSQpHe4+5PlhQmgDk0flVJkUrOs2/a+DTz7rOSe/OuVgfpLPjHsxyw1/MslnTCw7AOSrnP3wyVdlz4H0DJNH5VShd63gXe/e/S8+LHsx7EtfHe/wczWDCw+WdLa9PFmSfOS/jpkYADq1/RRKVXpfRtYt2542WbUfqy6zGPuPn6lJOF/pa+k82N33zd9bJKe7D0fsu2spFlJWr169bEPP/xwkMABVCOG2nMbDO7HSco8ZrbV3aeLxlC409bd3cxGnjXcfU7SnCRNT0+PP7sAiEpTbu4Ru8H9OKzMU/Z+zjsO/4dmdqAkpT8fDxcSALTfihWSmbRsWXXlsrwJ/8uS1qeP10v6tzDhAOiiply4FMrCgrRhg7R7d9LJu2lTNd+isgzLvFJJB+1KM3tU0oclfVTS583sLEkPS3pHmUECaK+yhizG3PfQK+fs3p208rdvH71uchI86IAQn5tllM5pI146PkQAALotby17qYQey7j3UbKOfur9HtIBB4X4XK60RaPE3GpDPpMkv97fXlo6odfRITqJ3tj9LVtGr7OwIF10kbRjR7jPJeGjMWJvtSGfLNMYDP7t169fOqE35fqBzZuTGAenYuj9vjt2JGWfUEj4aIzYW23Ib9zQz8G/vbR0Qi8yj05Vljqe+2v8y5ZJu3c//VSIzyThozGa0mpDeIN/+3XrRl/V2hP79QNLHc+Drz3zzPe/H+IzM11pG8r09LQvLi5W9nloH2r43TU3J119tXTKKdLsbN3RPF/e43Jcx3PvteOOC3OlLQkfQPRi7r+pIrZQUytwxysA0YtltslhYo5tEAkfQPR6Ne1hUw/XLebYBtFpCyB6w0bdxNKf04QRQT3U8AE0ThV181hOKFJE0yMDQNW2bHnuloJlXJMRcydxEdTwATTKwoJ02WVJspeS2nnounmTOmInQcIH0Cjz89LOncljM+nMM8O3vpvUETsJSjpABGKqF8du2FW3oTWpI3YSJHygZm2tF5elqmQc+9QMeZDwgZoxKdzk2piMq0ANH6hZW+vFiA8tfKBmS5UoqO0jJBI+EIFhJYou1PY5oVWLhA9Equ21/S6c0GJTqIZvZn9hZneb2V1mdqWZ7RUqMKDr2l7bL+PipoUFaePG5GcoZbxnXXK38M3sIEl/LulId3/GzD4v6VRJlweKDei0to4F7wl9B7MyvjG07VtI0ZLOckkvNLNfStpbUpDbcAFItHn4YegTWhklsLaV1XInfHd/zMz+XtIjkp6RdI27XzO4npnNSpqVpNWrV+f9OAAtFPKEVsY9j9t2H+Xc0yOb2X6Srpb0h5J+LOkLkq5y98+M2obpkQGEMGp0TxmjfmIYSRTD9MhvkvRdd9+WBvRFScdJGpnwAaCoperqZZTA2lRWKzJK5xFJrzWzvc3MJB0v6d4wYQGTK3s0RZtGazRZW6curkKRGv4tZnaVpFsl7ZT0v5LmQgUGTKLs0RRtG60xTAyliyzaVlevUqFROu7+YUkfDhQL8DyTJKCyR1Pkef/YE2h/fFI8J7Rx+63tw1XLxJW2iNKkLeqyW32Tvn/s3wgG41u/Po7hh1n3W5vq6lVitkxEadI6ba/Vd/HF5STXSd9/VPyx9AMMxifFcVUv9fly0cJHlPK02Iu0+rKUXyZ5/2Hxx9TqH3bXqHXr6i+TUJ8vFwkfUaqyTjuYiDdtkrZvL/a5w+LfuDGOssmo+HrL60R9vly5L7zKgwuvEKONG6ULL0wS8bJlyT/38K3wKlr4sXcUI58YLrwCWqG/jLBsWZL4d+9Onm/ZEi6B9lqvW7YECHqImEpGiBMJH7m0qSXZX0ZYsULasCFJmlNT0mWXSTt3hk2gmzcn7795c9ik3LaJvhAeCb/h6ki8sbck8+yT/g7Zo45Ktn/kEemTn0wS6LPPJi3zmGdfHNVR3JYTM4oj4TdYXYm37JZkkSQ1Nye95z1JSWbPPfPtk17yX1hIWvi7diU1/UsvTUayFPld845CyTqKqL/DU4r7xIzqkfAbbFziLat1V+bQuSInsYUF6ZxzkhKMJO3YUexkNDMjnXGGdMklScLftav4yS3PKJRJ9kn/N5Vxo4Jo/XcPCb/Blkq8Zbb+B2vevYtjQrx/kW8P8/PPJXsp6YAtejJat+65mnvek9tgYp30eoG8+2Tw+FixIjkJ0PrvLhJ+gy3VWiy77NJ7r9BJo8i3hxUrkpZ4z3nnhRtZk7clHOLEm3efjOqMjmkqBVSLhN9wo1qLVVyxWMZJZVSCzVJ+2L49adXv3p383HffYrH0x5T39wqxj4qcdHqxD5Z3JK5o7SISfgXqqJUWSZxZlXVS6cXVP49Kllby2rVJR21MSSzUPio6WVisUymgWq250jbWDqiYhjCWEUtZt5QbnMmxNzxyaiqZwOz886uLp6hYYoolDkyOK237xJRUB8V0MUx/LDt2SBddlPwrOuok9O8zaibHLK3k/iGVvQ7Kuo+FWKbyjSUO1KcVCT+mpDooptn/erHs2JHUub/+denGG+M6QUrFyw8xNwCAOrUi4ceUVAfFNPtfL5aLLkqSfW++mFAnyKVKBpOUE4rO5BhzAwDhUKLKwd0r+3fsscd6WW66yf0jH0l+dlmW/XDTTe4vfKH71FTyM8Q+W+o9y/i8rLHssYf72WdzXLRN1cdU3SQteoAc3Jo7Xs3MJB15XT7T90oZF16Y/Bx1V6VeCzrk3aGWulNR1Xcx6v1+73qXZJZ0+C61P9A83Bkrn0IJ38z2NbOrzOxbZnavmXU43dZvkv8EMzPJV+H5+TCJsFdWG3aLvKVeK8vMjLR6dXLlLUmhfeo4ptqgaA3/HyX9h7v/gZntIWnvADEhp0n6MkJ3bC7VV5G3H6NojTbmvh0UE1PfWJPkHodvZi+VdJukwzzjm+QZh0/HzGSy7q/+uzyNG9teh1AnJI4ftEEM4/APlbRN0mVm9hpJWyWd6+4/61/JzGYlzUrS6tWrJ/oAhtdNLutY69hbv6FG2jD2HHhOkRr+cknHSPoXdz9a0s8kfWBwJXefc/dpd59etWrVRB9Ax0w5eq3eTZvCdtyGRI0WCK9IC/9RSY+6+y3p86s0JOEXUWUrtCtf/UN8a6piX1GjBcLLnfDd/f/M7HtmdoS73yfpeEn3hAutuv/0VZaO6j6xFC2VVLmvKMcAYRUdpfNeSVekI3QelHRG8ZCer4r/9FVdmVl3n8TCQnKf1uXpXz3Pt6YtW5L7u7pzFSvQNIUSvrvfJqlwz3Gdeklwaip5XmbpqM5L/vtPNlNTyUVJk96fdWEhua9rb0zW8uXU1oEmacVcOnn1J8Hly/MlwUnk6ZMIVQLqP9lIyUVJk77f/Pxz25sl93uldQ80R+cSfn8CDZEEJzFpn0TIElCIDvBhs1i2Qd39KkBVOpXwBxPopk3Vj0WfpE8iZAkoRAd4G0fO1N2vAlSptQl/WKttMIFu3x53Ags9LDVEB3jbRs4wlTK6pJUJf1SrbVgCjTmBtbFFHZvYrzgGQmplwh/VamtiAo35hNQGTTwmgLyiTfhFOtKWarWRQDGIYwJdEWXCL9qRRqsNAH5dlAk/REcarbZ4MQwSqEeUCZ+OtPZiGCRQnygTPiWZ9mIYJFCfKBO+REmmrfj2BtQn2oSPduLbG1AfEj4qx7c3oB5FbnHYSAsLyQ28FxbyrT/p9mWJJQ4AzdGpFv6kI0SGTba2YUP9I0wY6QIgj9pa+HW0UCe9Kfrg+ldfHcdN1cu+uTvfHoB2qqWFX1cLddIRIoPrn3KKdOON9Y8wKXOkC98egPaqJeHXNRZ70hEiw9Y/6qj6R5iUOdKFcfJAe9WS8Osciz3pCJHB9WMYYVLm1ASMkwfaq3DCN7MpSYuSHnP3k7Js05Wx2GUk5rJLLl352wBdFKKFf66keyW9ZJKNqm4pVz1hV1mJOU/JZdLfPYZvMQDCK5TwzexgSW+V9LeSzgsSUQnq6IgsqxY+acmFTlgAPUWHZW6S9H5Ju0etYGazZrZoZovbtm2b+ANCDBEsexjjML3EPDUVthbeK7lcfHG25F3H7w4gTrlb+GZ2kqTH3X2rma0dtZ67z0mak6Tp6Wmf5DNCtU7r6IgssxY+ScmFTlgAPUVKOq+T9HYzO1HSXpJeYmafcfd3hgktXFmkro7IGGrhdMIC6DH3iRrdw98kaeH/5bhROtPT0764uJj5fak/A4BkZlvdfbro+0Q9lw6t0/pxO0KgPYIkfHeflzQf4r0GxVAW6Sq+YQHt0rnpkZEdI3yAdmlUwmcWx2qVNbQUQD2iruH3o7xQPfpQgHZpTMJnFsd60IcCtEdjSjqUFwCgmMa08CkvAEAxjUn4EuUFACgi6pIOo3IAIJxoW/iMygGAsKJt4XPRDwCEFW3CZ1QOAIQVbUmHUTkAEFa0CV/KNiqH2RwBIJuoE/44dOwCQHbR1vCzoGMXALJrdMKnYxcAsmt0SYeOXQDIrtEJX2K6BQDIqtElHQBAdiR8AOiI3AnfzA4xs+vN7B4zu9vMzg0ZGAAgrCI1/J2S3ufut5rZPpK2mtm17n5PoNgAAAHlbuG7+w/c/db08U8l3SvpoDzvxTTIAFC+IKN0zGyNpKMl3TLktVlJs5K0evXqX9uWq2UBoBqFO23N7MWSrpa0wd2fGnzd3efcfdrdp1etWvVr23O1LABUo1DCN7MXKEn2V7j7F/O8B1fLAkA1cpd0zMwkfVrSve7+D3nfh6tlAaAaRWr4r5P0x5LuNLPb0mUfdPevTvpGXC0LAOXLnfDd/b8kWcBYAAAl4kpbAOgIEj4AdAQJHwA6goQPAB1BwgeAjiDhA0BHkPABoCNI+ADQESR8AOgIEj4AdAQJHwA6goQPAB1BwgeAjiDhA0BHkPABoCNI+ADQESR8AOgIEj4AdAQJHwA6goQPAB1RKOGb2Qlmdp+Z3W9mHwgVFAAgvNwJ38ymJP2zpLdIOlLSaWZ2ZKjAAABhFWnh/6ak+939QXf/haTPSjo5TFgAgNCWF9j2IEnf63v+qKTfGlzJzGYlzaZPd5jZXQU+syorJf2o7iAyIM5wmhCjRJyhNSXOI0K8SZGEn4m7z0makyQzW3T36bI/syjiDKsJcTYhRok4Q2tSnCHep0hJ5zFJh/Q9PzhdBgCIUJGE/z+SDjezQ81sD0mnSvpymLAAAKHlLum4+04zO0fSf0qaknSpu989ZrO5vJ9XMeIMqwlxNiFGiThD61Sc5u4h3gcAEDmutAWAjiDhA0BHBEv446ZZMLM9zexz6eu3mNmavtfOT5ffZ2ZvDhVTjhjPM7N7zOwOM7vOzF7e99ouM7st/Vdq53SGOE83s2198fxJ32vrzew76b/1Ncf5sb4Yv21mP+57rZL9aWaXmtnjo67/sMQ/pb/DHWZ2TN9rVe7LcXH+URrfnWZ2k5m9pu+1h9Llt4UavlcgzrVm9pO+v+2H+l6rbCqWDHH+VV+Md6XH4/7pa5XsTzM7xMyuT3PO3WZ27pB1wh6f7l74n5JO2wckHSZpD0m3SzpyYJ0/k/SJ9PGpkj6XPj4yXX9PSYem7zMVIq4cMb5R0t7p4z/txZg+fzp0TAXiPF3Sx4dsu7+kB9Of+6WP96srzoH136ukY7/q/fnbko6RdNeI10+U9DVJJum1km6pel9mjPO43ucrmc7klr7XHpK0MpL9uVbSV4oeL2XHObDu2yR9o+r9KelAScekj/eR9O0h/9eDHp+hWvhZplk4WdLm9PFVko43M0uXf9bdd7j7dyXdn75faGNjdPfr3f3n6dOblVxbULUiU1a8WdK17v6Euz8p6VpJJ0QS52mSriwplpHc/QZJTyyxysmStnjiZkn7mtmBqnZfjo3T3W9K45DqOzaz7M9RKp2KZcI46zo2f+Dut6aPfyrpXiUzGPQLenyGSvjDplkYDPxX67j7Tkk/kbQi47ZVxdjvLCVn1p69zGzRzG42s98rIb6erHGekn7Fu8rMehfAVbUvJ/qstDR2qKRv9C2uan+OM+r3qHJfTmrw2HRJ15jZVkumMqnbjJndbmZfM7NXpsui3J9mtreSRHl13+LK96clJe6jJd0y8FLQ47P0qRWayMzeKWla0hv6Fr/c3R8zs8MkfcPM7nT3B+qJUP8u6Up332Fm71byzel3aooli1MlXeXuu/qWxbQ/G8PM3qgk4b++b/Hr0335MknXmtm30hZuHW5V8rd92sxOlPSvkg6vKZYs3ibpv929/9tApfvTzF6s5ISzwd2fKutzpHAt/CzTLPxqHTNbLumlkrZn3LaqGGVmb5J0gaS3u/uO3nJ3fyz9+aCkeSVn4zKMjdPdt/fF9ilJx2bdtso4+5yqga/MFe7PcUb9HtFNHWJmr1by9z7Z3bf3lvfty8clfUnllEQzcfen3P3p9PFXJb3AzFYqwv2ZWurYLH1/mtkLlCT7K9z9i0NWCXt8Bup8WK6k0+BQPdch88qBdd6j53fafj59/Eo9v9P2QZXTaZslxqOVdCwdPrB8P0l7po9XSvqOSupwyhjngX2Pf1/Szf5cR85303j3Sx/vX1ec6XqvUNIJZnXsz/Qz1mh0J+Nb9fxOsW9WvS8zxrlaSf/WcQPLXyRpn77HN0k6ocY4D+j9rZUkykfSfZvpeKkqzvT1lyqp87+ojv2Z7pctkjYtsU7Q4zNk8Ccq6WV+QNIF6bK/UdJSlqS9JH0hPWi/Kemwvm0vSLe7T9JbSjwAxsX4dUk/lHRb+u/L6fLjJN2ZHqR3Sjqr5AN1XJwbJd2dxnO9pFf0bXtmuo/vl3RGnXGmzy+S9NGB7Srbn0pabz+Q9Esldc6zJJ0t6ez0dVNyI58H0lima9qX4+L8lKQn+47NxXT5Yel+vD09Ji6oOc5z+o7Nm9V3ghp2vNQVZ7rO6UoGjPRvV9n+VFKWc0l39P1dTyzz+GRqBQDoCK60BYCOIOEDQEeQ8AGgI0j4ANARJHwA6AgSPgB0BAkfADri/wFsCLMlkQWDagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "plt.plot(X, y, 'b.')\n",
    "plt.axis([0, 2, 0, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d62b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.42953371]\n",
      " [1.         0.08584617]\n",
      " [1.         1.14230347]\n",
      " [1.         1.87365632]\n",
      " [1.         0.23867486]]\n"
     ]
    }
   ],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X]  # adds x0 = 1 to each set of x features\n",
    "print(X_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2b162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [2.96209733]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698a565",
   "metadata": {},
   "source": [
    "Note that function that we just used to generate the data is $y=4+3x_{1}+\\text{Gaussian noise}$. Now we can make predictions using $\\hat{\\mathbf{\\theta}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7862a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [9.90283441]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cd32d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, 'r-')\n",
    "plt.plot(X, y, 'b.')\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750780c",
   "metadata": {},
   "source": [
    "We can also perform linear regression with Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f46ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.97863974]), array([[2.96209733]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e860bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [9.90283441]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29cccd",
   "metadata": {},
   "source": [
    "The `LinearRegression` class is actually based on the `scipy.linalg.lstsq()` function. We can call that directly too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68831127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [2.96209733]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6)\n",
    "theta_best_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc21901",
   "metadata": {},
   "source": [
    "The `scipy.linalg.lstsq()` function computes $\\hat{\\mathbf{\\theta}}=\\mathbf{X}^{+}\\mathbf{y}$, where $\\mathbf{X}^{+}$ is the *pseudoinverse* of $\\mathbf{X}$. We can use `np.linalg.pinv()` to compute the pseudoinverse directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d644f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [2.96209733]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.pinv(X_b).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bdac7",
   "metadata": {},
   "source": [
    "The pseudoinverse is computed using a technique called *Singular Value Decomposition (SVD)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40d0a5",
   "metadata": {},
   "source": [
    "## Computational Complexity\n",
    "\n",
    "Clearly, the normal equation computes the inverse of $\\mathbf{X}^{\\text{T}}\\mathbf{X}$, but this is an $(n+1)\\times (n+1)$ matrix (where $n$ is the number of features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06479e",
   "metadata": {},
   "source": [
    "The computational complexity of inverting such a matrix is typically $O(n^{2.4})$ to $O(n^{3})$. On the other hand, the *Singular Value Decomposition (SVD)* approach used by Scikit-Learn's `LinearRegression` class does it with about $O(n^2)$ complexity. \n",
    "\n",
    ">While both the Normal Equation and SVD approach get very slow with increasing number of features, both are linear with regard to the number of instances in the training set (they are $O(m)$), so they can handle large training sets efficiently, provided they can fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3fc4e",
   "metadata": {},
   "source": [
    "Making *predictions* with a trained model, however, is very fast (almost linear).\n",
    "\n",
    "When there are a large number of features or too many training instances to fit in memory we have to get creative in order to reduce computational complexity and the training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2532814",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent is an iterative optimization algorithm that works by tweaking parameters and simultaneously minimizing a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909f213",
   "metadata": {},
   "source": [
    "How does gradient descent work?: It measures the local gradient of the error function (Calculus vibes) with respect to the parameter vector $\\mathbf{\\theta}$ and changes the parameters in the direction of the descending gradient. Once the gradient reaches zero, the function is minimized.\n",
    "\n",
    "Usually, $\\mathbf{\\theta}$ is populated with random values (*random initialization*). The parameters are tweaked slightly with the goal of decreasing the cost function (MSE, for example) until *convergence*.\n",
    "\n",
    "The size of the tweaks to the parameters $\\mathbf{\\theta}$ is deteremined by the *learning rate* hyperparameter. Getting the right learning rate is a balancing act: too small and the algortihm will take a long time to converge, and too large and the algorithm may diverge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c51acb",
   "metadata": {},
   "source": [
    "#### Not all cost functions are simple to minimize. \n",
    "\n",
    "They may have local minima which make gradient descent's job a lot harder. The algorithm may converge to a local minimum rather than the global one. Fortunately MSE for a LINEAR REGRESSION model is a *convex function*, meaning that the line segment between any two points on the curve never crosses the curve. This implies that there is only one minimum, and it's a global one. MSE is also a continuous function with a slope that does not change abruptly.\n",
    "\n",
    "All of these facts lead to one thing: gradient descent is guaranteed to approach arbitratiliy close to the global minimum!\n",
    "\n",
    "When using gradient descent, all features should have a similar scale or it will take longer to converge. The `StandardScaler` class in Scikit-Learn will do this for us.\n",
    "\n",
    "Training a model with gradient descent means searching for a combination of parameters within the parameter space that minimizes a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21590a46",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb63b06",
   "metadata": {},
   "source": [
    "To implement gradient descent we compute the gradient of the cost function with respect to *each* model parameter $\\theta_j$:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\theta_j} MSE(\\mathbf{\\theta})=\\frac{2}{m}\\sum^m_{i=1}\\Big(\\mathbf{\\theta}^T\\mathbf{x}^{(i)}-y^{(i)}\\Big)x_{j}^{(i)}$$\n",
    "\n",
    "Instead of computing this partial derivative for each and every model parameter, we can compute the gradient vector instead:\n",
    "\n",
    "$$ \\nabla_{\\theta}MSE(\\mathbf{\\theta})= \\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial \\theta_0} MSE(\\mathbf{\\theta})\\\\\n",
    "\\frac{\\partial}{\\partial \\theta_1} MSE(\\mathbf{\\theta})\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial}{\\partial \\theta_n} MSE(\\mathbf{\\theta})\n",
    "\\end{pmatrix} = \\frac{2}{m}\\mathbf{X}^{T}(\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y})$$\n",
    "\n",
    ">Notice that this formula involves calculations over the entire training set $\\mathbf{X}$ at each gradient descent step. Because the whole batch of training data is used at every step, this algorithm is very slow on large training sets. However, gradient descent scales well iwth the number of features; training a linear regression model when there are hundreds of thousands of features is still much faster using gradient descent than using the normal equation of singular value decomposition!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f75e80",
   "metadata": {},
   "source": [
    "The gradient vector in its current form points in the direction of greatest increase, so to go downhill we just subtract it from $\\mathbf{\\theta}$. Remember that the gradient vector is just a slope though, we need to multiply it by some constant to figure out how big of a step we will take! This is where we introduce the learning rate $\\eta$. We multiply $\\eta$ with the gradient vector to determine the size of the downhill step and then subtract that from $\\theta$, giving us a $\\theta$ that is slightly better than the previous:\n",
    "\n",
    "$$ \\mathbf\\theta^{\\text{next step}}=\\mathbf{\\theta}-\\eta\\nabla_{\\theta}MSE(\\mathbf{\\theta}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f90965",
   "metadata": {},
   "source": [
    "We can implement gradient descent really quickly in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d55fc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.97863974],\n",
       "       [2.96209733]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1 # learning rate\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2, 1)  \n",
    "# random initialization of theta, i.e. the parameter space which includes the \n",
    "# slope and intercept of the line we previously looked at\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    gradient = 2/m * X_b.T.dot(X_b.dot(theta)-y)\n",
    "    theta = theta - eta*gradient\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f10ec",
   "metadata": {},
   "source": [
    "This is exactly what the normal equation found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1934e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
